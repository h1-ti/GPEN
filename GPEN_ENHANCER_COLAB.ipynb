{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "GPEN_ENHANCER_COLAB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN4Oh9gSovMsnLfhpWEBptf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/h1-ti/GPEN/blob/main/GPEN_ENHANCER_COLAB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tJ_vcf2Rcsa"
      },
      "source": [
        "# **実行前の準備**\n",
        "\n",
        "\n",
        "\n",
        "1.   GOOGOLE DRIVE を開き左上の『＋新規』→　フォルダ　→　faceset フォルダを作成\n",
        "2.   ローカル（自分のパソコン）の 1)Faceset/CATEGORYフォルダ を開き、超解像したいSRCをzipで圧縮する。例）1)Faceset/hogezaka/hoge -> 1)Faceset/hogezaka/hoge.zip\n",
        "3.1のfacesetフォルダに2のhoge.zipをアップロード（複数可）\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kT9o8wr-XoPo"
      },
      "source": [
        "# **実行**\n",
        "\n",
        "\n",
        "\n",
        "* このページの上にある　ランタイム（左から５番目）　→　すべてのセルを実行\n",
        "\n",
        "## ※注意  **1.MOUNT GOOGLE DRIVE** のところで入力があります"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tg8amUD0jTUg"
      },
      "source": [
        "### 詳しく"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXLekaNXfH7J"
      },
      "source": [
        "* GOOGLE DRIVEのマウントが完了したら終わるまで待つだけです\n",
        "\n",
        "\n",
        "* 完了すると先ほどのfacesetフォルダにhoge_superres.zipができるのでドライブからダウンロードしてください\n",
        "\n",
        "\n",
        "* ※srcが多すぎると最後まで完了せずに接続が切れるかもしれません。時間をおいてやり直してください。完了したものはスキップされるようになっております\n",
        "\n",
        "* 実行中に新しいsrcのzipをアップすることも可能です\n",
        "\n",
        "\n",
        "* ※また、2.INSTALL and GET MODEL WEIGHTでダウンロードがうまくいかず止まっている場合はやり直してください"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQN1kTWtyNkz"
      },
      "source": [
        "**CHECK VIDEO CARD'S SPEC**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cvm0OvQVk-tS"
      },
      "source": [
        "速さ比較\n",
        "\n",
        " P100(?f/s) > T4(6f/s) > K80(3f/s)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWcpzkH4zygh",
        "outputId": "7f3f2e1a-8b5d-4bea-da12-9ec130723796"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Aug 20 17:18:37 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7jMlGY-x03o"
      },
      "source": [
        "# **1.MOUNT GOOGLE DRIVE**\n",
        "\n",
        "### ①Go to this URL in a browser:の右のリンクからGOOGLEにログイン\n",
        "### ②Enter your authorization code:の下に①で取得したコードをペーストしてGOOGLE DRIVE をマウント\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgkGoIv80oHK",
        "outputId": "24ce2cdd-7bcd-4cef-e1bc-fc09e87b784d"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LWZluDOxg1-"
      },
      "source": [
        "# **2.INSTALL and GET MODEL WEIGHT**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9RvF56eipf-"
      },
      "source": [
        "### install GPEN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w49XiZU8w_K0",
        "outputId": "f924e834-2503-4d91-a4b8-eee40713b3f0"
      },
      "source": [
        "%pip install ninja\n",
        "\n",
        "%cd /content\n",
        "!git clone https://github.com/h1-ti/GPEN.git"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ninja\n",
            "  Downloading ninja-1.10.2-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[?25l\r\u001b[K     |███                             | 10 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████                          | 20 kB 22.4 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 30 kB 17.3 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 40 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 51 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 61 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 71 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 81 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 92 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 102 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 108 kB 8.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.10.2\n",
            "/content\n",
            "Cloning into 'GPEN'...\n",
            "remote: Enumerating objects: 252, done.\u001b[K\n",
            "remote: Counting objects: 100% (252/252), done.\u001b[K\n",
            "remote: Compressing objects: 100% (221/221), done.\u001b[K\n",
            "remote: Total 252 (delta 41), reused 215 (delta 21), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (252/252), 47.88 MiB | 25.88 MiB/s, done.\n",
            "Resolving deltas: 100% (41/41), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IwOvQkPizw5"
      },
      "source": [
        "### get weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMi0s85HiYy1",
        "outputId": "72a75d1a-757a-4672-d414-9883efa0f24b"
      },
      "source": [
        "%cd /content/GPEN/weights\n",
        "!wget https://public-vigen-video.oss-cn-shanghai.aliyuncs.com/robin/models/RetinaFace-R50.pth\n",
        "!wget https://public-vigen-video.oss-cn-shanghai.aliyuncs.com/robin/models/GPEN-BFR-512.pth"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/GPEN/weights\n",
            "--2021-08-20 17:19:10--  https://public-vigen-video.oss-cn-shanghai.aliyuncs.com/robin/models/RetinaFace-R50.pth\n",
            "Resolving public-vigen-video.oss-cn-shanghai.aliyuncs.com (public-vigen-video.oss-cn-shanghai.aliyuncs.com)... 47.101.88.25\n",
            "Connecting to public-vigen-video.oss-cn-shanghai.aliyuncs.com (public-vigen-video.oss-cn-shanghai.aliyuncs.com)|47.101.88.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 109497761 (104M) [application/octet-stream]\n",
            "Saving to: ‘RetinaFace-R50.pth’\n",
            "\n",
            "RetinaFace-R50.pth  100%[===================>] 104.42M  3.33MB/s    in 26s     \n",
            "\n",
            "2021-08-20 17:19:39 (4.02 MB/s) - ‘RetinaFace-R50.pth’ saved [109497761/109497761]\n",
            "\n",
            "--2021-08-20 17:19:39--  https://public-vigen-video.oss-cn-shanghai.aliyuncs.com/robin/models/GPEN-BFR-512.pth\n",
            "Resolving public-vigen-video.oss-cn-shanghai.aliyuncs.com (public-vigen-video.oss-cn-shanghai.aliyuncs.com)... 47.101.88.25\n",
            "Connecting to public-vigen-video.oss-cn-shanghai.aliyuncs.com (public-vigen-video.oss-cn-shanghai.aliyuncs.com)|47.101.88.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 284085738 (271M) [application/octet-stream]\n",
            "Saving to: ‘GPEN-BFR-512.pth’\n",
            "\n",
            "GPEN-BFR-512.pth    100%[===================>] 270.92M  7.23MB/s    in 46s     \n",
            "\n",
            "2021-08-20 17:20:27 (5.91 MB/s) - ‘GPEN-BFR-512.pth’ saved [284085738/284085738]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aH9EtRb73CVY"
      },
      "source": [
        "# **3.FACE ENHANCE PROCESS**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBTNvtBH09Y8",
        "outputId": "660af8ea-4a29-4258-b945-2e20ae37fdc3"
      },
      "source": [
        "%cd /content/GPEN"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/GPEN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfJEX7oo28ne",
        "cellView": "form",
        "outputId": "fb638fd8-8ed3-4b6f-fdc9-8404c12bf2e9"
      },
      "source": [
        "#@title FACE ENHANCE PROCESS\n",
        "\n",
        "from face_enhancement import FaceEnhancement\n",
        "from tqdm import tqdm\n",
        "import os, os.path as osp\n",
        "import zipfile\n",
        "import glob\n",
        "import cv2\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "from DFLIMG.DFLPNG import DFLPNG\n",
        "from DFLIMG.DFLJPG import DFLJPG\n",
        "\n",
        "root = \"/content/GPEN\"\n",
        "\n",
        "model = {'name':'GPEN-BFR-512', 'size':512}\n",
        "    \n",
        "faceset_dir = \"/content/drive/MyDrive/faceset\"\n",
        "indir = osp.join(root, \"temp_input\")\n",
        "os.makedirs(indir, exist_ok=True)\n",
        "\n",
        "faceenhancer = FaceEnhancement(base_dir=root, size=model['size'], model=model['name'], channel_multiplier=2)\n",
        "\n",
        "done = []\n",
        "\n",
        "while True:\n",
        "    src_names = [osp.splitext(d)[0] for d in os.listdir(faceset_dir)\n",
        "             if osp.splitext(d)[1] == \".zip\" and \"_superres\" not in d\n",
        "             and not osp.exists(osp.join(faceset_dir, osp.splitext(d)[0]+\"_superres.zip\"))\n",
        "             and osp.splitext(d)[0] not in done]\n",
        "    if len(src_names) == 0:\n",
        "        break\n",
        "    print(src_names)\n",
        "    \n",
        "\n",
        "\n",
        "    for id, src in enumerate(src_names):\n",
        "        print(\"{} / {} [{}]\".format(id+1, len(src_names), src))\n",
        "        zip_path = osp.join(faceset_dir, src+\".zip\")\n",
        "        print(\"Extracting [{}] ...\".format(zip_path))\n",
        "        with zipfile.ZipFile(zip_path) as z:\n",
        "            z.extractall(indir)\n",
        "\n",
        "        files = sorted(glob.glob(osp.join(indir, src, '*.*g')))\n",
        "\n",
        "        outdir = osp.join(root, src+\"_superres\", src+\"_superres\")\n",
        "        os.makedirs(outdir, exist_ok=True)\n",
        "\n",
        "        for n, file in enumerate(tqdm(files[:], total=len(files), desc=\"Enhancing faces ...\")):\n",
        "            filename = osp.basename(file)\n",
        "            ext = osp.splitext(file)[1]\n",
        "            if ext == \".jpg\":\n",
        "                dflimg = DFLJPG.load(file)\n",
        "            elif ext == \".png\":\n",
        "                dflimg = DFLPNG.load(file)\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            if not dflimg:\n",
        "                continue\n",
        "            \n",
        "            im = cv2.imread(file, cv2.IMREAD_COLOR) # BGR\n",
        "            input_x, input_y = im.shape[:2]\n",
        "            if not isinstance(im, np.ndarray): print(filename, 'error'); continue\n",
        "            im = cv2.resize(im, (0,0), fx=2, fy=2)\n",
        "\n",
        "            img, orig_faces, enhanced_faces = faceenhancer.process(im)\n",
        "            img = cv2.resize(img, (input_x, input_y))\n",
        "            cv2.imwrite(osp.join(outdir, filename), img)\n",
        "\n",
        "            if ext == \".jpg\":\n",
        "                _fanseg_mask = dflimg.dfl_dict.get('fanseg_mask', None)\n",
        "                if _fanseg_mask is not None:\n",
        "                    ret, buf = cv2.imencode( '.jpg', _fanseg_mask, [int(cv2.IMWRITE_JPEG_QUALITY), 85] )\n",
        "\n",
        "                    if ret and len(buf) < 64000:\n",
        "                        _fanseg_mask = buf\n",
        "                    else:\n",
        "                        io.log_err(\"Unable to encode fanseg_mask for %s\" % (filename) )\n",
        "                        _fanseg_mask = None\n",
        "\n",
        "                _xseg_mask = dflimg.dfl_dict.get('xseg_mask', None)\n",
        "                if _xseg_mask is not None:\n",
        "                    ret, buf = cv2.imencode( '.jpg', _xseg_mask, [int(cv2.IMWRITE_JPEG_QUALITY), 85] )\n",
        "\n",
        "                    if ret and len(buf) < 64000:\n",
        "                        _xseg_mask = buf\n",
        "                    else:\n",
        "                        io.log_err(\"Unable to encode xseg_mask for %s\" % (filename) )\n",
        "                        _xseg_mask = None\n",
        "\n",
        "                DFLJPG.embed_dfldict (osp.join(outdir, filename), \n",
        "                                        {'face_type': dflimg.get_face_type(),\n",
        "                                            'landmarks': dflimg.get_landmarks(),\n",
        "                                            'ie_polys' : dflimg.get_ie_polys(),\n",
        "                                            'source_filename': dflimg.get_source_filename(),\n",
        "                                            'source_rect': dflimg.get_source_rect(),\n",
        "                                            'source_landmarks': dflimg.get_source_landmarks(),\n",
        "                                            'image_to_face_mat': dflimg.get_image_to_face_mat(),\n",
        "                                            'fanseg_mask' : _fanseg_mask,\n",
        "                                            'xseg_mask' : _xseg_mask,\n",
        "                                            'eyebrows_expand_mod' : None,\n",
        "                                            'relighted' : None,\n",
        "                                            \"histgram\" : None,\n",
        "                                            \"recognition\" : dflimg.get_recognition(),\n",
        "                                        })\n",
        "            elif ext == \".png\":\n",
        "                dflimg = DFLPNG.embed_dfldict (osp.join(outdir, filename), \n",
        "                                        {'face_type': dflimg.get_face_type(),\n",
        "                                            'landmarks': dflimg.get_landmarks(),\n",
        "                                            'ie_polys' : dflimg.get_ie_polys(),\n",
        "                                            'source_filename': dflimg.get_source_filename(),\n",
        "                                            'source_rect': dflimg.get_source_rect(),\n",
        "                                            'source_landmarks': dflimg.get_source_landmarks(),\n",
        "                                            'image_to_face_mat': dflimg.get_image_to_face_mat(),\n",
        "                                            'fanseg_mask' : dflimg.dfl_dict.get ('fanseg_mask', None),\n",
        "                                            'xseg_mask' : dflimg.dfl_dict.get('xseg_mask', None),\n",
        "                                            'eyebrows_expand_mod' : None,\n",
        "                                            'relighted' : None,\n",
        "                                            \"histgram\" : None,\n",
        "                                            \"recognition\" : dflimg.get_recognition(),\n",
        "                                        })\n",
        "\n",
        "\n",
        "        \n",
        "        shutil.make_archive(src+\"_superres\", 'zip', src+\"_superres\")\n",
        "        if osp.exists(osp.join(faceset_dir, src+\"_superres.zip\")):\n",
        "            os.remove(osp.join(faceset_dir, src+\"_superres.zip\"))\n",
        "        shutil.move(src+\"_superres.zip\", faceset_dir)\n",
        "        shutil.rmtree(src+\"_superres\")\n",
        "        print(\"Successfully completed {}\".format(src+\"_superres\"))\n",
        "        done.append(src)\n",
        "\n",
        "print(done)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['AshidaMana']\n",
            "1 / 1 [AshidaMana]\n",
            "Extracting [/content/drive/MyDrive/faceset/AshidaMana.zip] ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEnhancing faces ...:   0%|          | 0/7619 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "Enhancing faces ...:  39%|███▉      | 3003/7619 [08:07<12:24,  6.20it/s]"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}